{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf1204f-a89e-4b81-8b4f-82c3b2b09994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "        AutoTokenizer, \n",
    "        AutoModelForCausalLM,\n",
    "        BitsAndBytesConfig,\n",
    "        set_seed\n",
    "    )\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.tmarco import TMaRCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c009792f-4bed-422a-9f14-151a09aaaddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['filename', 'begin', 'end', 'challenging', 'prompt', 'continuation']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"allenai/real-toxicity-prompts\"\n",
    "raw_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "print(raw_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b3251a-aa8f-40f6-b923-6aaed19036cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(sample):\n",
    "    text = f\"Prompt: {sample['prompt']}\\n\\nContinuation: {sample['continuation']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8abccc6-bce1-42c4-b462-8b8125e34350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6569abecab44bc4970c8cd484fd5d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc8c4b3688f4db2a5a05f66b9698256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ca24516ce145bcbaa81957a58199e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9961c8598bb84b6189abdb220df767fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2f4491d41c45acbb43ce256b6d9689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620d52dc7ea34aeb9bab0c2dc89e8028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3b4ed904134075a30a27caa69ddc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f144f544e5d4f6980a19430fdfd9e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc33e3ff7dd45239e3a3a896d023214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f0e53f2ca94237933ba44fa32d6528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c87d54a7243f0895ddf5a433e661b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa455ce6b7d4958808ddf3ad391df02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/292 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmarco = TMaRCo()\n",
    "tmarco.load_models([\"trustyai/gminus\", \"trustyai/gplus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10404143-b3a5-4a29-9139-2658ba8bc50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_text(sample):\n",
    "    text = preprocess_text(sample)\n",
    "    scores = tmarco.score([text])\n",
    "    masked_outputs = tmarco.mask([text], scores=scores)\n",
    "    rephrased_text = tmarco.rephrase([text], scores=scores, masked_outputs=masked_outputs, threshold=0.6)\n",
    "    return rephrased_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c16957-e212-4060-af88-36df9be4d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "train_data = dataset[\"train\"]\n",
    "eval_data = dataset[\"test\"]\n",
    "print(f\"Size of training set: {len(train_data)}\\nSize of evaluation set: {len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f3a66-7b28-42a9-a241-6412d7df481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"facebook/opt-350m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d08bab-7ec6-41fc-9292-367fba4de862",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = min(tokenizer.model_max_length, 512)\n",
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    train_data,\n",
    "    formatting_func=rephrase_text,\n",
    "    seq_length=max_seq_length,\n",
    ")\n",
    "eval_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    eval_dataset,\n",
    "    formatting_func=preprocess_text,\n",
    "    seq_length=max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ae7be-434d-4c80-90b8-9914a2e26c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "device_map =  {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "\n",
    "model_kwargs = dict(\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c985c3-a635-431e-a366-213cd94e64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir = output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        auto_find_batch_size=True,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=1e-04,\n",
    "        max_grad_norm=0.3,\n",
    "        warmup_ratio=0.03,\n",
    "        lr_scheduler_type=\"cosine\"\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model_id,\n",
    "    model_init_kwargs=model_kwargs, \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=peft_config,\n",
    "    packing=True,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22feb53-4d2a-41c7-98c7-43288b17d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9a7f6-1bbf-4992-81ce-9095d07f524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"opt-350m_DETOXIFY_CAUSAL_LM\"\n",
    "\n",
    "token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "model.push_to_hub(output_dir, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8ade3-fbc3-4cce-b170-733a41e6d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
