{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5765762-6239-4ed0-ace2-cba6ec00a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.tmarco import TMaRCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a737b97b-94dd-45aa-8633-b058565ec6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c0c2e6bf4b433a9bf502448df88e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/35.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b92f3e56e394edca9177cb96bed8a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5efa263062940caa1ab8aaa76db053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4efa9643a5b47ee9b916be3f83e163a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8276e1b7139413e873749dd4ac3bd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/127656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e78dbbc81d4e9e8d4d191591fea566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/31915 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd77a338c6ba4499909470b4951738bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/63978 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabdf6c4345a43f08e4e659623c5e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating balanced_train split:   0%|          | 0/25868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ba3f62f30b4fa9ba11a8dd3310f449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/63978 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'comment_text', 'label']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"OxAISH-AL-LLM/wiki_toxic\", split=\"test\")\n",
    "dataset = dataset.filter(lambda x: x[\"label\"] == 1 )\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fbc4c-37a9-4d97-87a7-6115e6837910",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "# load into pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e9bfd-7bb1-42d5-948c-30fcd4885d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sample):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434d65f-1f0e-49d4-84f2-45f01fd7d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [\"facebook/opt-350m\", \"../models/opt-350m-\"]\n",
    "\n",
    "toxicities = {}\n",
    "\n",
    "for model_id in tqdm(models_to_test):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    toxicities[model_id] = []\n",
    "    \n",
    "    for text in enumerate(tqdm(dataset)):\n",
    "        inputs = tokenizer(\n",
    "            f\"Prompt: {text}/n/n Continuation:\",\n",
    "            truncation = True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], \n",
    "                max_new_tokens=256,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.95\n",
    "              )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.detach().cpu().numpy(), \n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "        output_list.append(outputs[0])\n",
    "        \n",
    "        toxicities[model_id] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
